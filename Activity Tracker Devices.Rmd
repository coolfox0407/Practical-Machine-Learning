---
title: 'Coursera: Practical Machine Learning - Project'
author: "Hariharan D"
date: "16 September 2017"
output: 
  html_document:
    fig_width: 9
    fig_height: 9
---

<style>
body {
text-align: justify}
</style>

### 1.Introduction

This project assignment is part of "Practical Machine Learning" course at Coursera's "Data Science" specialization. Goal of this project is to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants and obtain a prediction algorithm that correctly predicts the type of class (A to E), which is the **"classe"** variable in the training set. This project uses the "Weight Lifting Exercises" dataset. More information on this dataset is available **[here](http://groupware.les.inf.puc-rio.br/har)**. 

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify **"how much"** of a particular activity they do, but they rarely quantify **"how well"** they do it.

Six young health participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E). Class A corresponds to the specified execution of the exercise, while the other 4 classes correspond to common mistakes.

Dataset will be analyzed using exploratory analysis and the following ML algorithms will be used to model the training datasets. Best one of the below three ML algorithms will be used for predictions in the test dataset.

1. Decision Tree
2. Random Forests
3. Generalized Boosted Regression

### 2.Data Source:

Dataset for this project is sourced from this **[website](http://groupware.les.inf.puc-rio.br/har)**

* Training Data is available here **[pml-training.csv](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv)**

* Test Data is available here **[pml-testing.csv](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv)**


### 3.Set Options and Load R Libraries

Set the chunk options.

```{r Set Options, include = TRUE}

library(knitr)

knitr::opts_chunk$set(echo = TRUE, tidy = TRUE, warning = FALSE, message = FALSE, fig.align = "center")

```

Load the necessary libraries.

Note: It is assumed that the below libraries are aready installed.

```{r R Library}

library(caret)
library(rpart)
library(rpart.plot)
library(rattle)
library(randomForest)
library(corrplot)
library(Rmisc)
library(ggplot2)
library(RColorBrewer)

```


### 4.Load Dataset and Clean the Data

Loading the dataset.

```{r Load Dataset}

set.seed(12345)

trainURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"

testURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

training <- read.csv(url(trainURL), na.strings=c("NA","#DIV/0!",""))

testing <- read.csv(url(testURL), na.strings=c("NA","#DIV/0!",""))

# Creating partition with Training dataset

trainData <- createDataPartition(training$classe, p=0.7, list=FALSE)
trainingSet <- training[trainData, ]
testingSet <- training[-trainData, ]

dim(trainingSet)
dim(testingSet)

```

Cleansing the data by removing "Near Zero Variance (NZV)", "NA" and ID variables.

```{r Clean Data}

# Removing "NZV"

NZV <- nearZeroVar(trainingSet)
trainingSet <- trainingSet[, -NZV]
testingSet  <- testingSet[, -NZV]

dim(trainingSet)
dim(testingSet)

# Removing "NA"

dataNA <- sapply(trainingSet, function(x) mean( is.na(x) ) ) > 0.95
trainingSet <- trainingSet[, dataNA == FALSE]
testingSet  <- testingSet[, dataNA == FALSE]

dim(trainingSet)
dim(testingSet)

# Removing ID variables

trainingSet <- trainingSet[, -(1:5)]
testingSet  <- testingSet[, -(1:5)]

dim(trainingSet)
dim(testingSet)

```


### 5.Exploratory Analysis


```{r Correlation Analysis}

# Correlation Analysis

corMatrix <- cor(trainingSet[, -54])
corrplot(corMatrix, order = "FPC", method = "color", type = "lower", tl.cex = 0.6, tl.col = rgb(0, 0, 0))

```

The highly correlated variables are shown in dark blue square fills in the correlation plot. Let us now verify the dataspread characteristics visually using GGPLOT. 

```{r Multi-plot Analysis}

# Multi-plot Analysis

p1 <- ggplot(trainingSet, aes(classe, pitch_forearm)) + geom_boxplot(aes(fill=classe))

p2 <- ggplot(trainingSet, aes(classe, magnet_arm_x)) + geom_boxplot(aes(fill=classe))

multiplot(p1,p2,cols=2)

```

From the above plot, we can infer that there is no clear separation of classes.

### 6.Prediction Model - Machine Learning Algorithms

#### 6.1.Decision Tree

```{r Decision Tree}

# Model Fit

set.seed(12345)

fitDecisionTree <- rpart(classe ~ ., data = trainingSet, method="class")
fancyRpartPlot(fitDecisionTree)

# Prediction on Testing Dataset

predictDecisionTree <- predict(fitDecisionTree, newdata = testingSet, type="class")
confMatDecisionTree <- confusionMatrix(predictDecisionTree, testingSet$classe)
confMatDecisionTree

# Plotting Confusion Matrix

plot(confMatDecisionTree$table, col = confMatDecisionTree$byClass, main = paste("Decision Tree Confusion Matrix Accuracy : ", round(confMatDecisionTree$overall['Accuracy'], 4)*100, "%"))

```


#### 6.2. Random Forests

```{r Random Forests}

# Model fit

set.seed(12345)

controlRF <- trainControl(method = "cv", number = 3, verboseIter = FALSE)
fitRandomForests <- train(classe ~ ., data = trainingSet, method = "rf", trControl = controlRF)
fitRandomForests$finalModel

# Prediction on Testing Dataset

predictRandomForests <- predict(fitRandomForests, newdata = testingSet)
confMatRandomForests <- confusionMatrix(predictRandomForests, testingSet$classe)
confMatRandomForests

# Plotting Confusion Matrix

plot(confMatRandomForests$table, col = confMatRandomForests$byClass, main = paste("Random Forests Confusion Matrix Accuracy : ", round(confMatRandomForests$overall['Accuracy'], 4)*100, "%"))

```

#### 6.3. Generalized Boosted Regression

```{r Generalized Boosted Regression}

# Model fit

set.seed(12345)

controlGBR <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
fitGBR  <- train(classe ~ ., data = trainingSet, method = "gbm", trControl = controlGBR, verbose = FALSE)
fitGBR$finalModel

# Prediction on Testing Dataset

predictGBR <- predict(fitGBR, newdata = testingSet)
confMatGBR <- confusionMatrix(predictGBR, testingSet$classe)
confMatGBR

# Plotting Confusion Matrix

plot(confMatGBR$table, col = confMatGBR$byClass, main = paste("GBR Confusion Matrix Accuracy : ", round(confMatGBR$overall['Accuracy'], 4)*100, "%"))

```


### 7.Predicting Results on Test Dataset with Selected Model

The accuracy of above 3 Prediction Models are as follows;

1. Decision Tree: **`r round(confMatDecisionTree$overall['Accuracy'], 4)*100`%**
2. Random Forests: **`r round(confMatRandomForests$overall['Accuracy'], 4)*100`%**
3. Generalized Boosted Regression: **`r round(confMatGBR$overall['Accuracy'], 4)*100`%**

The expected out-of-sample error of **Random Forests is `r 100*(1-round(confMatRandomForests$overall['Accuracy'], 4))`%.**, which is least among all the above selected models. Hence Random Forests model will be used to predict the test dataset.

```{r Predict TestData}

# Predict Test Data

set.seed(12345)

predictTEST <- predict(fitRandomForests, newdata = testing)
predictTEST

```
